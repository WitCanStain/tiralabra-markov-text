## Määrittelydokumentti ##

The purpose of this project by a Computer Science student (tietojenkäsittelytieteen kandidaatti) is to model text generation with Markov chains. The main data structures implemented will be trie and hashmap, and possibly matrices as well. The algorithms used will be a stochastic Markov process utilising tree search, along with associated utility algorithms for parsing the training data and creating the trie. The idea is to parse the training data given to the program, split it into words, and insert those words into a trie in order to enable the Markov process to traverse the tree and probabilistically determine the next word (state) following the _n_ previous words. This will allow us to achieve an efficiency of O(_m_) for each generated sentence of m words. Such a structure would then have a storage requirement of at least O(_N*m*k_), where _m_ is as before, _N_ is the number of distinct words in the corpus and _k_ is the number of different _m_-length chains (sentences) represented by the trie. The program will take any body of text as its input, and will be provided with a few pre-selected texts. The input will be treated as the training data for the Markov process, and a new trie will be generated by parsing the data and determining the frequency of each word, as well as the possibilities for the next _n_ words following each word.

The documentation, comments and code of this project will be in English.


Sources:

https://medium.com/basecs/trying-to-understand-tries-3ec6bede0014

https://setosa.io/ev/markov-chains/

https://www.kdnuggets.com/2019/11/markov-chains-train-text-generation.html

